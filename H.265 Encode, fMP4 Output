#include <opencv2/opencv.hpp>
#include <iostream>
#include <vector>
#include <memory>
#include <algorithm>

extern "C" {
#include <libavformat/avformat.h>
#include <libavcodec/avcodec.h>
#include <libavutil/opt.h>
#include <libavutil/imgutils.h>
#include <libswscale/swscale.h>
#include <libavutil/hwcontext.h>
}

static AVFrame* process_frame(AVFrame* frame) {
    uint8_t* y_plane = frame->data[0];
    int y_stride = frame->linesize[0];
    for (int y = 0; y < frame->height; y++) {
        for (int x = 0; x < frame->width; x++) {
            int val = y_plane[y * y_stride + x];
            val = std::min(255, val + 30);
            y_plane[y * y_stride + x] = val;
        }
    }
    return frame;
}

int main(int argc, char* argv[]) {
    if (argc < 3) {
        std::cerr << "Kullanım: " << argv[0] << " input.mp4 output.mp4\n";
        return -1;
    }

    const char* input_file = argv[1];
    const char* output_file = argv[2];

    avformat_network_init();

    AVFormatContext* fmt_ctx = nullptr;
    if (avformat_open_input(&fmt_ctx, input_file, nullptr, nullptr) < 0) {
        std::cerr << "Giriş dosyası açılamadı: " << input_file << "\n";
        return -1;
    }
    if (avformat_find_stream_info(fmt_ctx, nullptr) < 0) {
        std::cerr << "Stream bilgisi alınamadı\n";
        return -1;
    }

    int video_stream_index = -1;
    for (unsigned int i = 0; i < fmt_ctx->nb_streams; i++) {
        if (fmt_ctx->streams[i]->codecpar->codec_type == AVMEDIA_TYPE_VIDEO) {
            video_stream_index = i;
            break;
        }
    }
    if (video_stream_index == -1) {
        std::cerr << "Video stream bulunamadı\n";
        return -1;
    }

    AVCodecParameters* codecpar = fmt_ctx->streams[video_stream_index]->codecpar;
    const AVCodec* decoder = avcodec_find_decoder(codecpar->codec_id);
    if (!decoder) {
        std::cerr << "Decoder bulunamadı\n";
        return -1;
    }
    AVCodecContext* decoder_ctx = avcodec_alloc_context3(decoder);
    avcodec_parameters_to_context(decoder_ctx, codecpar);

    AVBufferRef* hw_device_ctx = nullptr;
    if (av_hwdevice_ctx_create(&hw_device_ctx, AV_HWDEVICE_TYPE_NONE, nullptr, nullptr, 0) < 0) {
        std::cerr << "Donanım cihazı oluşturulamadı, devam ediliyor...\n";
    } else {
        decoder_ctx->hw_device_ctx = av_buffer_ref(hw_device_ctx);
    }

    if (avcodec_open2(decoder_ctx, decoder, nullptr) < 0) {
        std::cerr << "Decoder açılamadı\n";
        return -1;
    }

    AVFormatContext* out_fmt_ctx = nullptr;
    avformat_alloc_output_context2(&out_fmt_ctx, nullptr, "mp4", output_file);
    if (!out_fmt_ctx) {
        std::cerr << "Çıktı formatı oluşturulamadı\n";
        return -1;
    }

    const AVCodec* encoder = avcodec_find_encoder_by_name("libx265");
    if (!encoder) {
        std::cerr << "libx265 encoder bulunamadı\n";
        return -1;
    }

    AVStream* out_stream = avformat_new_stream(out_fmt_ctx, nullptr);
    AVCodecContext* encoder_ctx = avcodec_alloc_context3(encoder);
    encoder_ctx->height = decoder_ctx->height;
    encoder_ctx->width = decoder_ctx->width;
    encoder_ctx->sample_aspect_ratio = decoder_ctx->sample_aspect_ratio;
    encoder_ctx->pix_fmt = AV_PIX_FMT_YUV420P;
    encoder_ctx->time_base = av_inv_q(decoder_ctx->framerate);
    if (encoder_ctx->time_base.num == 0 || encoder_ctx->time_base.den == 0)
        encoder_ctx->time_base = fmt_ctx->streams[video_stream_index]->time_base;
    encoder_ctx->bit_rate = 4000000;

    encoder_ctx->hw_device_ctx = av_buffer_ref(hw_device_ctx);

    if (encoder->id == AV_CODEC_ID_HEVC) {
        av_opt_set(encoder_ctx->priv_data, "preset", "fast", 0);
        av_opt_set(encoder_ctx->priv_data, "tune", "zerolatency", 0);
    }

    if (avcodec_open2(encoder_ctx, encoder, nullptr) < 0) {
        std::cerr << "Encoder açılamadı\n";
        return -1;
    }

    avcodec_parameters_from_context(out_stream->codecpar, encoder_ctx);
    out_stream->time_base = encoder_ctx->time_base;

    if (!(out_fmt_ctx->oformat->flags & AVFMT_NOFILE)) {
        if (avio_open(&out_fmt_ctx->pb, output_file, AVIO_FLAG_WRITE) < 0) {
            std::cerr << "Çıktı dosyası açılamadı\n";
            return -1;
        }
    }

    av_dict_set(&out_fmt_ctx->metadata, "movflags", "frag_keyframe+empty_moov", 0);
    if (avformat_write_header(out_fmt_ctx, nullptr) < 0) {
        std::cerr << "Header yazılamadı\n";
        return -1;
    }

    AVPacket* pkt = av_packet_alloc();
    AVFrame* frame = av_frame_alloc();
    AVFrame* filt_frame = nullptr;
    AVFrame* rgb_frame = av_frame_alloc();
    int num_bytes = av_image_get_buffer_size(AV_PIX_FMT_BGR24, decoder_ctx->width, decoder_ctx->height, 1);
    uint8_t* buffer = new uint8_t[num_bytes];
    av_image_fill_arrays(rgb_frame->data, rgb_frame->linesize, buffer, AV_PIX_FMT_BGR24, decoder_ctx->width, decoder_ctx->height, 1);
    struct SwsContext* sws_ctx = sws_getContext(decoder_ctx->width, decoder_ctx->height, decoder_ctx->pix_fmt, decoder_ctx->width, decoder_ctx->height, AV_PIX_FMT_BGR24, SWS_BILINEAR, nullptr, nullptr, nullptr);
    int64_t pts = 0;

    while (av_read_frame(fmt_ctx, pkt) >= 0) {
        if (pkt->stream_index == video_stream_index) {
            if (avcodec_send_packet(decoder_ctx, pkt) < 0)
                break;
            while (avcodec_receive_frame(decoder_ctx, frame) == 0) {
                filt_frame = process_frame(frame);
                filt_frame->pts = pts++;

                avcodec_send_frame(encoder_ctx, filt_frame);
                while (avcodec_receive_packet(encoder_ctx, pkt) == 0) {
                    pkt->stream_index = out_stream->index;
                    av_packet_rescale_ts(pkt, encoder_ctx->time_base, out_stream->time_base);
                    av_interleaved_write_frame(out_fmt_ctx, pkt);
                    av_packet_unref(pkt);
                }

                sws_scale(sws_ctx, frame->data, frame->linesize, 0, decoder_ctx->height, rgb_frame->data, rgb_frame->linesize);
                cv::Mat img(decoder_ctx->height, decoder_ctx->width, CV_8UC3, rgb_frame->data[0], rgb_frame->linesize[0]);
                cv::imshow("Video Frame", img);
                if (cv::waitKey(25) == 27) goto cleanup;

                av_frame_unref(frame);
            }
        }
        av_packet_unref(pkt);
    }

    avcodec_send_frame(encoder_ctx, nullptr);
    while (avcodec_receive_packet(encoder_ctx, pkt) == 0) {
        pkt->stream_index = out_stream->index;
        av_packet_rescale_ts(pkt, encoder_ctx->time_base, out_stream->time_base);
        av_interleaved_write_frame(out_fmt_ctx, pkt);
        av_packet_unref(pkt);
    }

    av_write_trailer(out_fmt_ctx);

cleanup:
    delete[] buffer;
    av_frame_free(&rgb_frame);
    sws_freeContext(sws_ctx);
    av_frame_free(&frame);
    av_packet_free(&pkt);
    avcodec_free_context(&decoder_ctx);
    avcodec_free_context(&encoder_ctx);
    avformat_close_input(&fmt_ctx);
    if (!(out_fmt_ctx->oformat->flags & AVFMT_NOFILE))
        avio_closep(&out_fmt_ctx->pb);
    avformat_free_context(out_fmt_ctx);
    av_buffer_unref(&hw_device_ctx);
    avformat_network_deinit();
    cv::destroyAllWindows();

    return 0;
}
